{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vg-dBiXRAnjh"
   },
   "source": [
    "# Notebook 4: GRPO Reasoning Training\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BalaAnbalagan/modern-ai-unsloth/blob/main/colab4_grpo_reasoning.ipynb)\n",
    "\n",
    "**Author**: Balamuralikrishnan Anbalagan  \n",
    "**Objective**: Demonstrate reasoning training with GRPO on GSM8K math data source\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "In this runbook demonstrates **Group Relative Policy Optimization (GRPO)** for reasoning tasks. We'll:\n",
    "- Use GSM8K data source (grade school math problems)\n",
    "- Train model to show explicit reasoning before answering\n",
    "- Implement custom reward function for math accuracy\n",
    "- Measure accuracy improvement before/after training\n",
    "- Generate structured reasoning outputs\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8r3sivoAnji"
   },
   "source": [
    "## 1. Installation & Setup\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TtOdbGXHAnji"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install Unsloth and dependencies\n",
    "# What's happening: Installing libraries for reinforcement learning-based training\n",
    "# Key libraries for GRPO:\n",
    "#   - unsloth: Optimizes RL training (faster policy updates, efficient sampling)\n",
    "#   - trl: Contains trainers for RL methods (PPO, GRPO, etc.)\n",
    "#   - peft: LoRA implementation for parameter-efficient RL fine-tuning\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers trl peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OLnoUcNAnjj",
    "outputId": "8e71fa59-10b4-4f87-f6d5-dc5f102f0f66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA A100-SXM4-40GB\n",
      "GPU Memory: 39.56 GB\n",
      "BF16 Support: True\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU availability\n",
    "# What's happening: Checking GPU for RL training\n",
    "# GRPO note: Requires less memory than PPO (no value function network needed)\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"BF16 Support: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9sJ_SuKAnjj"
   },
   "source": [
    "## 2. Load & Prepare GSM8K Dataset\n",
    "\n",
    "GSM8K contains 8.5K grade school math problems requiring multi-step reasoning\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414,
     "referenced_widgets": [
      "6ef8233dd05544fcad39784772619fde",
      "98153624106d4ac59b55680446082539",
      "d0e9aa5e89484092a8244a2c3c4a4169",
      "aade1c27c7494e78b7129f9282b6ca68",
      "39ef8432bb9445178b4af44f760b8827",
      "f721a06c1f9b43bc9ba330bb584850ba",
      "659f940e182d49a4b09bfb1e85feed45",
      "5d8002664ee3431084da0c07bbdf0b4c",
      "c83e3c237cb9448ab1b7a9db064db0b4",
      "b28993e1201049b2a4e35a12a573021d",
      "c7bca2fafa8b4be5ac2015f0554dc544",
      "fe2e14355ef542a2839c6d6a8dadeb3b",
      "7274dc8ca3cf42539b7cb19419dba5e3",
      "6511be3f449745a796c9cc4dfa958638",
      "19d6fcfd07fc4374a34cb26273f4759b",
      "1ddbf7759c1947a988d3666f6f699005",
      "17a49990b4df43378ebc1015d2ed750c",
      "0525c4d3a9954ee6b0b9a44c21436581",
      "b35353d2543c4b19b24a582aa9b5d210",
      "b75b1b061db3453eab2ad381ad063770",
      "95052b4fd4ca4b66a07c848ddef88231",
      "11fb02d61bbe40c1a33a48ef848b370f",
      "4c21ac6a8fd04d1ab1f5b1f26493ed7a",
      "5f994d223a614f65b8275d0f31d60b59",
      "970b0931d93a411b8a37f4e7b0213e03",
      "257481eeed484a66a1b97b3c56d4687e",
      "b0487b31151846e09c90186f239d899b",
      "dc8ecfdb510846eaa43c999e5e2e4094",
      "c273b19c72e2481f9081a8245b797ecf",
      "3bd7f247d4cd437dbe9f4631e0442c1d",
      "f23e8b83312a426bb93a0121fd8745b3",
      "8003101cb49a4cf1b6b83d8697bf41d1",
      "31705a83ca6b43bb8bdd46e1d4dcec23",
      "208678b4e4cb4e508bf9f984af5e63fd",
      "60ae26a0894748eda5cf7caab47546aa",
      "3f328a438f2c4dbdb4f9305f7a8eb09e",
      "5b39d41739fd4ffa936ea613d16de735",
      "3a546cd5223445c3923a280cab450679",
      "66c7a6a3c5814f69959dc558f6c16675",
      "e5bee10c4775439c9cbb70c8cdc8857b",
      "a115f9536e4046cab4edeedf0310484a",
      "10fe175fc44e4dad80edbaf15028642f",
      "a4847d7f74a2479ab779306686088f35",
      "54747cdd42354ba6b896ab479d762a24",
      "985e38a8728e4b32885bc92f7cb08ff8",
      "aec0eee90f1a475cb34032776d97ffdb",
      "e28a8ae14bb34b0aa8239c720817ca9e",
      "5b5c8ad5abf646f69f70d677a9b6f0bc",
      "7a7d18054d14456ea79a389b277105d2",
      "3edbdb6124404ee4947ff78750996604",
      "54b2236a05cf4b9dbb87980791d6ab63",
      "e4267aded806470189921477c6760560",
      "c46e68c72b5f479e83642659cfd23281",
      "32426ef239704c0892c7969b044d1fa9",
      "eda8f58ffd8e4983802fc183ce430109",
      "b93588de5239458686c08dc48c69e9ea",
      "9c6ac5c3da4644cfae317ec1fdbe26d3",
      "33a1eaac4e984f3489e674494c3c8564",
      "4f50788eec8544bd94b88de864346366",
      "cbd69c932f804755a98b64f80281b89a",
      "9376cb5e2c144bc78f29fb8e375f6c59",
      "6399c6ed7b9740a1aebc498f1fc91d1c",
      "2f00ddd7cde842f0820f216ecddbb930",
      "d4ecba44282545d5a5b576c3cc8817c6",
      "7449aafbe78a4cefa6506d1c5144a4bc",
      "2794b6a14bb94ab19be6ed9b12435cd2",
      "74d0f69bc5844212abb6b9dc6bfe1a39",
      "c1a3ae8df14344aca677fb25e18dc05e",
      "cb4cd6dd8596428982199af75b743a08",
      "6fd585ba25204004bc96360e1e27b9c8",
      "4dfed7ee4a38491bb017da56593b47e9",
      "8aaeb1477f2d4f1bbd662e34e72c1f14",
      "20afb88460a5477aba9173b6439e6676",
      "88d5dd372161470db4952faf62d2d5bd",
      "e4e4d4a2abce4d109118c31a3abf4766",
      "a30330c0d8644b04bc07dcc8fc38f54f",
      "bdd021ee5f4a41938e6706f39fe775fa",
      "2e844dbd5e2c4d72931211035a5cb79b",
      "0b65cac04fe54bc98aa9a3d293a3db4c",
      "667282432b7e4807b09853123166adb9",
      "2cbcbdc78e064a79b5735214d349c3ab",
      "9ad8aac10da64aada62f5084c8110ea2",
      "387a8a2b3b834fbdaf934326ce071554",
      "0d591201586044ba81664aa00afd29be",
      "1b5e5dacab4043af95a881a9f0d6f545",
      "92b80f0e66c044dbb3aa404f63cd940f",
      "cb5b3730cbd44e62be3143c7082095a2",
      "2dc1d0fe5fca483f9bceb7e703f2661f",
      "d36c0189378e4012893fe2d807942a1c",
      "891abb19fe6343cda09801dd24029bcb",
      "b45236b8675e4e30a28eb34f97f68093",
      "66a221afe41b4477bd9a62fbcc83001f",
      "4a2f31f21f764cd5a33d07265edc5b80",
      "d9890a96da2242ab8a2237537624195f",
      "7c1444dfc5984720ba6e13bec5649f60",
      "b777cfc13f4944ed9e0f783049d583df",
      "8ca64353a384480b821c4eea732b38c1",
      "ca07d800d1804886af58324fa09c3f58",
      "3aa75a6fa7af46fd830d3c59e6998eb5"
     ]
    },
    "id": "qNJGTbFrAnjj",
    "outputId": "4741b445-932b-4688-b273-4a0f4914891b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load: EleutherAI/asdiv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef8233dd05544fcad39784772619fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/494 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2e14355ef542a2839c6d6a8dadeb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "asdiv/validation-00000-of-00001.parquet:   0%|          | 0.00/267k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c21ac6a8fd04d1ab1f5b1f26493ed7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: EleutherAI/asdiv Unknown split \"train\". Should be one of ['validation'].\n",
      "Trying to load: yimingzhang/asdiv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208678b4e4cb4e508bf9f984af5e63fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985e38a8728e4b32885bc92f7cb08ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/131k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93588de5239458686c08dc48c69e9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/34.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d0f69bc5844212abb6b9dc6bfe1a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e844dbd5e2c4d72931211035a5cb79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: yimingzhang/asdiv size: 1200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36c0189378e4012893fe2d807942a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example mapped row: {'messages': [{'content': 'You are a careful math tutor. Show brief reasoning, then finish with: Final Answer: <number>.', 'role': 'system'}, {'content': \"Solve the problem and end with 'Final Answer: <number>'.\\\\n\\\\nQuestion: A pet supply store has 600 bags of dog food and 327 bags of cat food. How many more bags of dog food are there than cat food?\\nAnswer:\", 'role': 'user'}], 'answer': '273'}\n"
     ]
    }
   ],
   "source": [
    "# === Data: ASDiv (new dataset, robust loader) ===\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Try a few public datasets in order; stop at the first that loads.\n",
    "CANDIDATE_DATASETS = [\n",
    "    (\"EleutherAI/asdiv\", None),       # ASDiv (preferred)\n",
    "    (\"yimingzhang/asdiv\", None),      # ASDiv mirror\n",
    "    (\"openai/gsm8k\", \"main\"),         # GSM8K\n",
    "    (\"allenai/math_qa\", None),        # MathQA (multiple-choice)\n",
    "]\n",
    "\n",
    "def try_load_dataset(candidates):\n",
    "    last_err = None\n",
    "    for path, subset in candidates:\n",
    "        try:\n",
    "            print(f\"Trying to load: {path}\" + (f\" / {subset}\" if subset else \"\"))\n",
    "            ds = load_dataset(path, subset, split=\"train\")\n",
    "            print(f\"Loaded: {path}\" + (f\" / {subset}\" if subset else \"\"), \"size:\", len(ds))\n",
    "            return path, subset, ds\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"Failed: {path}\", e)\n",
    "    raise last_err\n",
    "\n",
    "ds_name, ds_subset, raw = try_load_dataset(CANDIDATE_DATASETS)\n",
    "\n",
    "# Keep a manageable subset for quick demos\n",
    "try:\n",
    "    sample_n = cfg.train_sample_size if hasattr(cfg, \"train_sample_size\") else 800\n",
    "except:\n",
    "    sample_n = 800\n",
    "if sample_n and sample_n < len(raw):\n",
    "    raw = raw.shuffle(seed=42).select(range(sample_n))\n",
    "\n",
    "SYSTEM = \"You are a careful math tutor. Show brief reasoning, then finish with: Final Answer: <number>.\"\n",
    "\n",
    "# Heuristics to pick question/answer keys across variants\n",
    "QUESTION_CANDIDATES = [\"question\", \"Question\", \"body\", \"Body\", \"text\", \"Text\", \"Problem\", \"problem\"]\n",
    "ANSWER_CANDIDATES   = [\"answer\", \"Answer\", \"ans\", \"Ans\", \"final_answer\", \"FinalAnswer\", \"label\", \"result\", \"Result\", \"solution\", \"Solution\"]\n",
    "\n",
    "def pick_key(example, keys):\n",
    "    for k in keys:\n",
    "        if k in example and example[k] is not None:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "def normalize_gold(answer_field):\n",
    "    # Extract a number if possible; fallback to raw text\n",
    "    if answer_field is None:\n",
    "        return \"\"\n",
    "    s = str(answer_field)\n",
    "    m = re.search(r\"([-+]?\\\\d+(?:\\\\.\\\\d+)?)\", s.replace(\",\", \"\"))  # strip commas like 1,234\n",
    "    return m.group(1) if m else s.strip()\n",
    "\n",
    "def to_prompt(example):\n",
    "    qk = pick_key(example, QUESTION_CANDIDATES)\n",
    "    ak = pick_key(example, ANSWER_CANDIDATES)\n",
    "    q = example.get(qk, \"\") if qk else \"\"\n",
    "    a = example.get(ak, \"\") if ak else \"\"\n",
    "\n",
    "    # MathQA is multiple-choice; its golden answer can be a letter. We still keep it,\n",
    "    # but our reward prefers numeric matches. Thatâ€™s fine for GRPO demos; for MC tasks\n",
    "    # you could change the reward later to check the correct option letter.\n",
    "    gold = normalize_gold(a)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"Solve the problem and end with 'Final Answer: <number>'.\\\\n\\\\n{q}\"}\n",
    "    ]\n",
    "    return {\"messages\": messages, \"answer\": gold}\n",
    "\n",
    "ds = raw.map(to_prompt, remove_columns=[c for c in raw.column_names if c not in [\"messages\",\"answer\"]])\n",
    "print(\"Example mapped row:\", ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206,
     "referenced_widgets": [
      "2096c3a8b75140f39000560e3d0719d6",
      "cea6af4753e04ee2b3388711a26881d8",
      "5772d5e9b373472dadc85e839fca2edd",
      "7a1b618edc414683ad3abaf0bbc6c81d",
      "ed8521cf7eee4ef0a128f4f2ec14902f",
      "f2259d6d56114d96a6a9f7606b5eed89",
      "1f0f44db34814051a1b0d69b4a83ab93",
      "bfc6fbfefd9e48748108f032736a0ecf",
      "91aa5d4508e349389f57e1c4a1844740",
      "e0f333b6b11a412aabdf11bfc4e93cf2",
      "a6d28d521e5342088b3e84e545af5545",
      "c96d57b529ad42018427d2b86b8e48e8",
      "7b3704c94bfe494898349fcba741e6bf",
      "a4a4b5ef91294aaf996340ae7c293617",
      "19d4276eb5b54170a300974d033b5f36",
      "9cf26da0677e4ef6bed864ed5316d166",
      "9a1567192dc04951b2a9cf84ed65ae32",
      "99370abd4c6b40ac91e21b78bc1278e9",
      "2e0f2ba2d22d4d4ea9d927e5483244ac",
      "a2e9a9d0ff6447d68c4f3f15e520973a",
      "54fb496cf73049daabd4aabb5d5f58f4",
      "e75db82ab2f24e08a5e015b7eb0e740d"
     ]
    },
    "id": "KzUVIhpYAnjj",
    "outputId": "9f0508c2-8531-478c-d256-daa4399fed74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train/test splits...\n",
      "âœ“ Split complete: train=720  test=80\n",
      "Formatting datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2096c3a8b75140f39000560e3d0719d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96d57b529ad42018427d2b86b8e48e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Datasets formatted for GRPO training\n",
      "Sample keys: dict_keys(['answer', 'prompt', 'full_solution'])\n",
      "System role: system User len: 0\n",
      "Answer (normalized): 0\n"
     ]
    }
   ],
   "source": [
    "# ===== Robust split + formatting for GRPO (GSM8K / ASDiv / MathQA compatible) =====\n",
    "import re\n",
    "\n",
    "# 0) Use the dataset you already loaded earlier\n",
    "print(\"Preparing train/test splits...\")\n",
    "if \"ds\" in locals():\n",
    "    base = ds\n",
    "elif \"raw\" in locals():\n",
    "    base = raw\n",
    "else:\n",
    "    raise ValueError(\"No dataset found. Make sure the data-loading cell ran (it should define `ds` or `raw`).\")\n",
    "\n",
    "# If you already have a split, keep it; otherwise make one\n",
    "if \"train\" in base and \"test\" in base:\n",
    "    train_dataset = base[\"train\"]\n",
    "    test_dataset  = base[\"test\"]\n",
    "else:\n",
    "    split = base.train_test_split(test_size=0.1, seed=42)\n",
    "    train_dataset = split[\"train\"]\n",
    "    test_dataset  = split[\"test\"]\n",
    "print(f\"âœ“ Split complete: train={len(train_dataset)}  test={len(test_dataset)}\")\n",
    "\n",
    "# 1) Define SYSTEM if not already set\n",
    "if \"SYSTEM\" not in globals():\n",
    "    SYSTEM = (\n",
    "        \"You are a friendly, careful math tutor. \"\n",
    "        \"Think step by step and finish your response with: Final Answer: <number>.\"\n",
    "    )\n",
    "\n",
    "# 2) Guess column names across datasets\n",
    "QUESTION_KEYS = [\"question\", \"Question\", \"body\", \"Body\", \"text\", \"Text\", \"Problem\", \"problem\", \"prompt\"]\n",
    "ANSWER_KEYS   = [\"answer\", \"Answer\", \"ans\", \"Ans\", \"final_answer\", \"FinalAnswer\", \"label\", \"result\", \"Result\", \"solution\", \"Solution\"]\n",
    "\n",
    "# 3) Extract an answer that GRPO can score\n",
    "def extract_answer_text(ans):\n",
    "    s = str(ans)\n",
    "    # GSM8K: ends with \"#### 123\"\n",
    "    m = re.search(r\"####\\s*([-+]?\\d+(?:\\.\\d+)?)\", s)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # Generic number (handles ASDiv and many others)\n",
    "    m = re.search(r\"([-+]?\\d+(?:\\.\\d+)?)\", s.replace(\",\", \"\"))\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # Multiple-choice (MathQA): pick A/B/C/D if present\n",
    "    m = re.search(r\"\\b([A-D])\\b\", s)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return s.strip()\n",
    "\n",
    "# 4) Format for your friendâ€™s GRPO pipeline\n",
    "def format_for_grpo(example):\n",
    "    qk = pick_key(example, QUESTION_KEYS)\n",
    "    ak = pick_key(example, ANSWER_KEYS)\n",
    "    q  = example.get(qk, \"\") if qk else \"\"\n",
    "    a  = example.get(ak, \"\") if ak else \"\"\n",
    "    return {\n",
    "        # Your friendâ€™s trainer later converts \"prompt\" (chat messages) to text via chat template\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\",   \"content\": q},\n",
    "        ],\n",
    "        \"answer\": extract_answer_text(a),   # concise gold for reward\n",
    "        \"full_solution\": str(a),            # keep original for reference\n",
    "    }\n",
    "\n",
    "# 5) Map formatting\n",
    "print(\"Formatting datasets...\")\n",
    "train_dataset = train_dataset.map(format_for_grpo, remove_columns=[c for c in train_dataset.column_names if c not in [\"prompt\",\"answer\",\"full_solution\"]])\n",
    "test_dataset  = test_dataset.map(format_for_grpo,  remove_columns=[c for c in test_dataset.column_names  if c not in [\"prompt\",\"answer\",\"full_solution\"]])\n",
    "print(\"âœ“ Datasets formatted for GRPO training\")\n",
    "\n",
    "# 6) Quick sanity check (won't crash if dataset is empty)\n",
    "try:\n",
    "    sample = train_dataset[0]\n",
    "    print(\"Sample keys:\", sample.keys())\n",
    "    print(\"System role:\", sample[\"prompt\"][0][\"role\"], \"User len:\", len(sample[\"prompt\"][1][\"content\"]))\n",
    "    print(\"Answer (normalized):\", sample[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(\"Sanity check skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XUTc8f1Anjj"
   },
   "source": [
    "## 3. Load Model & Tokenizer\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452,
     "referenced_widgets": [
      "8ddc2e20025b4644a38a92ba9b596771",
      "951f9074d80b4e398ef68400734825d5",
      "06729059784442028cf466a52cce43d3",
      "c254ad3895b44b6c8706b7683d9995e4",
      "28bf4026828241c5803724d0190e3ad2",
      "54f50ddd6ff64668a8d4e6ae9bb5f5f4",
      "d1c58d9651c749efb7918d454c4ac1a1",
      "bbd4bd3781104b5391013589e1b26dff",
      "0016014d9d5545f29ca9e9ec690162ff",
      "e023cf7394be4cada6354d8d49da1faa",
      "0c5672aac77a4dbc8782d403ad1e3126",
      "f21bc09e83344f399d55d6109eb2f2c0",
      "0ba32ac912f848918b887163ce44d9cc",
      "4e39b811de624f2292698ec5981b8515",
      "8f69969b25224497b2237a7d59b1fa17",
      "3553015798714a60b8c0bb95dfda2190",
      "bdf4cfb597e742e4a2f79da995aea096",
      "0764fd4d4fbe44e4afbb87645a31944c",
      "cb141331632247e2bdcf8a2d173af099",
      "b20bda1238ac4a63858601cef34d6a9a",
      "cd451295bf2f4986a4ee85d379888963",
      "61fcef608bda4e67a6d8320744f65670",
      "875a8a0f320a4daab1d533440899c3ce",
      "eaf14b91368a4d0da5e156b68a22cd28",
      "b04b6d86e221427ca252f950c73d4c6d",
      "2ceeb7721d084f8da88cf7d926e5773d",
      "f3ecf1b6435c4f1db19daa22dc60158c",
      "7a6069c22d5943339662adfc6e63cea4",
      "1cf7a77e5ef54c879cd59f624917e50e",
      "971773472eaf4d33ae6499c9960d02dc",
      "b25e248163b04c6ca0b1e70fa8c7f052",
      "6c06e03f4fdb4e4794430defc07f9725",
      "32e8d7a18d794e16811bc42db0597995",
      "11dd8964bbcc4fd69048259c91e7becf",
      "8cebcc87e327471f876f817da7f016cd",
      "d3e08456daee4cc186cb206bd062556c",
      "e57a9e02accf4900b81f94ea97b269a5",
      "b3c366ee186941ecbdddc7b9754e55d8",
      "67457ebc40744df8aa90d1198858d031",
      "055008c3e9054404953c054bef1e8241",
      "185c94d58dcc42119dcb89ee3f27a75b",
      "3aa57d79a70e429889728cb8860868d5",
      "fa6e3db7cb83415d9309d1100a0f3eed",
      "d280919b343c4007ae9a8aaf6891c92e",
      "e24d0521e1704e319b523cd4727c1cec",
      "61a1c633b7bf4defa20120b2e7e9195f",
      "9dded5d11379412384f6bba8fda907ce",
      "c86b844907cd40ea93c7e3d994552292",
      "4dde88f2ec7a435a9db6f383e961e25c",
      "ef527fc8ac5c4de5b33659cf702c88b9",
      "b39d3285fc1c4ee0bc599338cd239ee5",
      "e41075bb612640329cfa210120462ac9",
      "d6d4d764259544d9b167f3f97a134bd7",
      "e8d8af6dd0fd4ab9988b3df6d7b4375b",
      "19bfad81323b4d04970a2902ac25c090",
      "6203567970234cdea0564f95ae1e2f9e",
      "4735350a973c409b85a8214e9e5d100d",
      "ad8a9e0b8262412bbdb6c13fed1af890",
      "f886c2367153440282a400abd7b73c17",
      "3a0ec58d095c4bf18fec2a2c6433b6a2",
      "742b36d60de2433085ec2be84a70914e",
      "85d51dc31322416a8e45d773e216de4a",
      "692d4f2064d345b1bb71c3c0cd40e0fa",
      "10ea192682014dd1b2e4e1fa77fd4a4b",
      "56d00efb81954f1c93ea86e8c952891a",
      "6c9d75632de547108cb385df7dc5cc05",
      "29d16b59823147718d59e79e8fab8bff",
      "a50cfa29aafb44c9859788288159a62f",
      "85c978786d8f46d3913b16955956e2c4",
      "f16bc65a93be4bbf9ae930862f6f1499",
      "aea8fec3c25943fd9622cdebe8543acf",
      "3b0967d0b7154f5494ebe0f2bcdf8108",
      "1a2c8d49c2d14ce5b687cabc579c1368",
      "766179d0c03a4de2a5551993a1c4386b",
      "127a4345a06845ce8dc6be19328534c7",
      "6357a63f21724fdd971c2b7ba6b989de",
      "34e7280836674416ba1fe14235d314e6",
      "18eb34df7d2146aab9bfec8bafd01ac5",
      "21b18a27b18e4a7e99b8803d4d8d842d",
      "6511efec389047d8a8fecaa06e5c2905",
      "f8fccd076ccb45a8b210cbce66164a9d",
      "b663088ffee74895945b3a6931ea943c",
      "9f58759254524ca192a3474ff2f1975d",
      "96b303f642874c54bb1fa5f979e8646f",
      "1ba4449958b24a16bb2e60dc505723fd",
      "946c69712bed4798877d99ce957ce803",
      "cc66f43e32e74617bb11f589dfe37e9a",
      "4a854da0d71e4b4ca3eb48169d869496"
     ]
    },
    "id": "2LX_6bLaAnjj",
    "outputId": "26103e00-12e2-44b6-80b1-7d510365c128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.11.2: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddc2e20025b4644a38a92ba9b596771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21bc09e83344f399d55d6109eb2f2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875a8a0f320a4daab1d533440899c3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dd8964bbcc4fd69048259c91e7becf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24d0521e1704e319b523cd4727c1cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6203567970234cdea0564f95ae1e2f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d16b59823147718d59e79e8fab8bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/742 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18eb34df7d2146aab9bfec8bafd01ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded: unsloth/smollm2-135m\n",
      "âœ“ Total parameters: 134,515,584\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "# Load model and tokenizer\n",
    "# What's happening: Loading SmolLM2-135M for reasoning training\n",
    "# Why this model size:\n",
    "#   - Small enough to train quickly\n",
    "#   - Large enough to learn reasoning patterns\n",
    "#   - Good for demonstrating GRPO concepts\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/smollm2-135m\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "# Ensure padding token is set\n",
    "# Why: RL training generates multiple responses per prompt (needs batching)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(f\"âœ“ Model loaded: {model.config._name_or_path}\")\n",
    "print(f\"âœ“ Total parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD31lNIUAnjk"
   },
   "source": [
    "## 4. Test Baseline Accuracy (Before Training)\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVjrp9pUAnjk",
    "outputId": "d8dd23c7-52b0-4138-d761-463d6d7b5706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BASELINE ACCURACY (Before GRPO Training)\n",
      "================================================================================\n",
      "\n",
      "Evaluating on 50 samples...\n",
      "  Evaluated 10/50 samples...\n",
      "  Evaluated 20/50 samples...\n",
      "  Evaluated 30/50 samples...\n",
      "  Evaluated 40/50 samples...\n",
      "  Evaluated 50/50 samples...\n",
      "\n",
      "âœ“ Baseline Results:\n",
      "  Correct: 0/50\n",
      "  Accuracy: 0.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1) A safe ChatML-style default template (works for most instruct models)\n",
    "DEFAULT_CHAT_TEMPLATE = r\"\"\"{% for m in messages -%}\n",
    "{% if m['role'] == 'system' -%}\n",
    "<|im_start|>system\n",
    "{{ m['content'] }}<|im_end|>\n",
    "{% elif m['role'] == 'user' -%}\n",
    "<|im_start|>user\n",
    "{{ m['content'] }}<|im_end|>\n",
    "{% elif m['role'] == 'assistant' -%}\n",
    "<|im_start|>assistant\n",
    "{{ m['content'] }}<|im_end|>\n",
    "{% endif -%}\n",
    "{% endfor -%}\n",
    "{% if add_generation_prompt -%}\n",
    "<|im_start|>assistant\n",
    "{% endif -%}\"\"\"\n",
    "\n",
    "def extract_model_answer(text: str) -> str:\n",
    "    \"\"\"Try several ways to get the model's numeric answer.\"\"\"\n",
    "    # 1) <answer>...</answer> tags\n",
    "    if \"<answer>\" in text and \"</answer>\" in text:\n",
    "        inside = text.split(\"<answer>\")[1].split(\"</answer>\")[0]\n",
    "        nums = re.findall(r\"-?\\d+\\.?\\d*\", inside.replace(\",\", \"\"))\n",
    "        if nums:\n",
    "            return nums[-1]\n",
    "    # 2) 'Final Answer: ...'\n",
    "    m = re.search(r\"Final\\s*Answer\\s*:\\s*(-?\\d+\\.?\\d*)\", text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    # 3) fallback: last number anywhere\n",
    "    nums = re.findall(r\"-?\\d+\\.?\\d*\", text.replace(\",\", \"\"))\n",
    "    return nums[-1] if nums else \"\"\n",
    "\n",
    "def _to_prompt_text_from_messages(msgs):\n",
    "    \"\"\"Convert messages -> prompt text. Use tokenizer template if present, else our default.\"\"\"\n",
    "    # Prefer tokenizer's own template if it exists\n",
    "    tmpl = getattr(tokenizer, \"chat_template\", None)\n",
    "    try:\n",
    "        if tmpl is not None:\n",
    "            return tokenizer.apply_chat_template(\n",
    "                msgs, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "        # Otherwise pass our default as an explicit template param\n",
    "        return tokenizer.apply_chat_template(\n",
    "            msgs, tokenize=False, add_generation_prompt=True, chat_template=DEFAULT_CHAT_TEMPLATE\n",
    "        )\n",
    "    except Exception:\n",
    "        # Final fallback: manual stitch\n",
    "        parts = []\n",
    "        for m in msgs:\n",
    "            parts.append(f\"<|im_start|>{m['role']}\\n{m['content']}<|im_end|>\")\n",
    "        parts.append(\"<|im_start|>assistant\\n\")\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "def evaluate_accuracy(model, tokenizer, dataset, num_samples=50):\n",
    "    \"\"\"Evaluate model accuracy on math problems.\"\"\"\n",
    "    # Optional Unsloth speedup if available\n",
    "    try:\n",
    "        from unsloth import FastLanguageModel\n",
    "        FastLanguageModel.for_inference(model)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    n = min(num_samples, len(dataset))\n",
    "    print(f\"\\nEvaluating on {n} samples...\")\n",
    "\n",
    "    for i, example in enumerate(dataset.select(range(n))):\n",
    "        # The formatting step produced example[\"prompt\"] as messages\n",
    "        if isinstance(example.get(\"prompt\"), list):\n",
    "            msgs = example[\"prompt\"]\n",
    "            # Ensure first message is system; prepend if missing\n",
    "            if not msgs or msgs[0].get(\"role\") != \"system\":\n",
    "                msgs = [{\"role\": \"system\", \"content\": SYSTEM}] + msgs\n",
    "            prompt_text = _to_prompt_text_from_messages(msgs)\n",
    "        else:\n",
    "            # string prompt fallback\n",
    "            prompt_text = f\"{SYSTEM}\\n\\n{str(example.get('prompt',''))}\\n\\n\"\n",
    "\n",
    "        inputs = tokenizer([prompt_text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=256,\n",
    "                temperature=0.2,      # low temp for math\n",
    "                top_p=0.95,\n",
    "                do_sample=True,\n",
    "                use_cache=True,\n",
    "                pad_token_id=(getattr(tokenizer, \"pad_token_id\", None) or getattr(tokenizer, \"eos_token_id\", None)),\n",
    "            )\n",
    "\n",
    "        full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Keep only the completion part if the prompt is echoed\n",
    "        completion = full_text.split(prompt_text)[-1]\n",
    "\n",
    "        model_answer = extract_model_answer(completion)\n",
    "        true_answer = str(example.get(\"answer\", \"\")).strip()\n",
    "\n",
    "        # compare as floats with small tolerance\n",
    "        try:\n",
    "            if model_answer and true_answer:\n",
    "                if abs(float(model_answer) - float(true_answer)) < 1e-2:\n",
    "                    correct += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        total += 1\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Evaluated {i+1}/{n} samples...\")\n",
    "\n",
    "    acc = (correct / total) if total else 0.0\n",
    "    return acc, correct, total\n",
    "\n",
    "# ==== Run baseline ====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE ACCURACY (Before GRPO Training)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_acc, baseline_correct, baseline_total = evaluate_accuracy(\n",
    "    model, tokenizer, test_dataset, num_samples=50\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Baseline Results:\")\n",
    "print(f\"  Correct: {baseline_correct}/{baseline_total}\")\n",
    "print(f\"  Accuracy: {baseline_acc*100:.1f}%\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvSiTgL3Anjk"
   },
   "source": [
    "## 5. Apply LoRA for GRPO Training\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJef18tWAnjk",
    "outputId": "5d73db56-c5cb-41c0-e0f8-7f7fb38f3f42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.11.2 patched 30 layers with 30 QKV layers, 30 O layers and 30 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ LoRA Applied for GRPO Training\n",
      "  Trainable params: 4,884,480\n",
      "  Total params: 139,400,064\n",
      "  Trainable %: 3.50%\n"
     ]
    }
   ],
   "source": [
    "# Apply LoRA\n",
    "# What's happening: Adding LoRA adapters with rank=16 for reasoning training\n",
    "# Why rank 16:\n",
    "#   - Higher than simple task adaptation (8) but lower than DPO (64)\n",
    "#   - Reasoning needs moderate expressiveness\n",
    "#   - Balances performance and efficiency\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,  # Moderate rank for reasoning tasks\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,  # No dropout for RL training (helps stability)\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    ")\n",
    "\n",
    "# Calculate trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = model.num_parameters()\n",
    "print(f\"\\nâœ“ LoRA Applied for GRPO Training\")\n",
    "print(f\"  Trainable params: {trainable_params:,}\")\n",
    "print(f\"  Total params: {total_params:,}\")\n",
    "print(f\"  Trainable %: {trainable_params/total_params*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWLz67l1Anjk"
   },
   "source": [
    "## 6. Define GRPO Reward Function\n",
    "\n",
    "The reward function evaluates math accuracy and reasoning structure\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bHj_swYAnjk",
    "outputId": "8b71adba-1542-4d32-aa14-8c975f628ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Reward function defined with 4 components:\n",
      "  1. Correct answer: +3.0 points (most important!)\n",
      "  2. Reasoning tags: +1.0 point (show your work)\n",
      "  3. Answer tags: +1.0 point (clean output)\n",
      "  4. Detailed reasoning: +0.5 points (explain thoroughly)\n",
      "  Maximum reward: 5.5 points\n",
      "\n",
      "  How Unsloth helps: Efficiently computes rewards for multiple samples in parallel\n"
     ]
    }
   ],
   "source": [
    "def math_reward_function(samples, prompts, outputs, tokenizer, **kwargs):\n",
    "    \"\"\"Custom reward function for GRPO math training.\n",
    "\n",
    "    What's happening: Defining how to score model outputs\n",
    "    This is the \"teacher\" that tells the model what's good/bad\n",
    "\n",
    "    GRPO Concept:\n",
    "      - In reinforcement learning, we need a reward signal\n",
    "      - Higher reward = better output (model learns to maximize this)\n",
    "      - Think of it like grades in school: model learns what gets high scores\n",
    "\n",
    "    How this works:\n",
    "      1. Model generates multiple answers for each question\n",
    "      2. Each answer gets a reward score (0-5.5 points)\n",
    "      3. GRPO ranks answers by reward (relative comparison)\n",
    "      4. Model learns to generate higher-reward responses\n",
    "\n",
    "    Args:\n",
    "        samples: List of dataset samples (contains correct answers)\n",
    "        prompts: List of prompt texts\n",
    "        outputs: List of generated outputs from the model\n",
    "        tokenizer: The tokenizer\n",
    "\n",
    "    Returns:\n",
    "        List of rewards (one score per output)\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "\n",
    "    for sample, output in zip(samples, outputs):\n",
    "        reward = 0.0\n",
    "\n",
    "        # Decode output if needed\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            output_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        else:\n",
    "            output_text = output\n",
    "\n",
    "        # Reward 1: Correct answer (+3.0 points) - MOST IMPORTANT\n",
    "        # This is the main goal: getting the right numerical answer\n",
    "        model_answer = extract_model_answer(output_text)\n",
    "        true_answer = sample.get('answer', '')\n",
    "\n",
    "        try:\n",
    "            if model_answer and true_answer:\n",
    "                model_num = float(model_answer)\n",
    "                true_num = float(true_answer)\n",
    "                if abs(model_num - true_num) < 0.01:  # Allow tiny rounding errors\n",
    "                    reward += 3.0  # Big reward for correct answer!\n",
    "                else:\n",
    "                    reward -= 1.0  # Penalty for wrong answer (discourages guessing)\n",
    "        except:\n",
    "            reward -= 1.0  # Penalty for invalid format (like outputting text instead of numbers)\n",
    "\n",
    "        # Reward 2: Proper reasoning structure (+1.0 point)\n",
    "        # We want the model to show its work using <reasoning> tags\n",
    "        if \"<reasoning>\" in output_text and \"</reasoning>\" in output_text:\n",
    "            reward += 1.0\n",
    "\n",
    "        # Reward 3: Proper answer structure (+1.0 point)\n",
    "        # We want clean final answers in <answer> tags\n",
    "        if \"<answer>\" in output_text and \"</answer>\" in output_text:\n",
    "            reward += 1.0\n",
    "\n",
    "        # Reward 4: Reasoning length (encourage explanation) (+0.5 point)\n",
    "        # We want detailed explanations, not just one-word reasoning\n",
    "        if \"<reasoning>\" in output_text:\n",
    "            reasoning_text = output_text.split(\"<reasoning>\")[1].split(\"</reasoning>\")[0]\n",
    "            if len(reasoning_text.split()) > 10:  # At least 10 words of explanation\n",
    "                reward += 0.5\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards\n",
    "\n",
    "print(\"âœ“ Reward function defined with 4 components:\")\n",
    "print(\"  1. Correct answer: +3.0 points (most important!)\")\n",
    "print(\"  2. Reasoning tags: +1.0 point (show your work)\")\n",
    "print(\"  3. Answer tags: +1.0 point (clean output)\")\n",
    "print(\"  4. Detailed reasoning: +0.5 points (explain thoroughly)\")\n",
    "print(\"  Maximum reward: 5.5 points\")\n",
    "print(\"\\n  How Unsloth helps: Efficiently computes rewards for multiple samples in parallel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SHXPROuAnjk"
   },
   "source": [
    "## 7. Configure GRPO Training\n",
    "\n",
    "**Note**: Full GRPO training with TRL's GRPOTrainer requires significant setup. For this demo, we'll use a simplified supervised fine-tuning approach with reasoning-focused examples.\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "52d0c8fa3f2546eeb3b310c7323115f1",
      "713c82e0920a4cf59785ae837ee0bde8",
      "00b4f83e2a7344eb85537d7ca715b3d2",
      "5195e81ab558449ca917f6cae113cb57",
      "accd78b3b5204e07b42f69ad50352e8b",
      "14ae8dd89b6a46ed9e9056ef07147dda",
      "36e2872efbec4c579448964d3e17c806",
      "c76d147f8d214fa884090acd36fd1c07",
      "f38975783af34c83909e837c3fbc938b",
      "a8222a484c0645e5a98a2db028992329",
      "dc211f6e2b7b48cc8ddb0cefe71f5329"
     ]
    },
    "id": "3OU6a6MeAnjl",
    "outputId": "2f90fc6c-ff1c-458b-9ade-1f55b8f914c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting datasets for SFT...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d0c8fa3f2546eeb3b310c7323115f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ train_formatted example: You are a careful math tutor. Show brief reasoning, then finish with: Final Answer: <number>.  User:   Assistant: <reasoning> 0 </reasoning>  <answer> 0 </answer>...\n",
      "âœ“ Training configuration:\n",
      "  Approach: Supervised Fine-Tuning with Reasoning\n",
      "  Batch size: 1\n",
      "  Gradient accumulation: 8\n",
      "  Max steps: 200\n",
      "  Learning rate: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# ===== Supervised formatting + TrainingArguments (robust to schema) =====\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import os, re, torch\n",
    "\n",
    "# 0) Ensure a system prompt exists (use your earlier SYSTEM if present)\n",
    "if \"SYSTEM_PROMPT\" not in globals():\n",
    "    SYSTEM_PROMPT = (SYSTEM if \"SYSTEM\" in globals() else\n",
    "                     \"You are a careful math tutor. Show your reasoning briefly, then finish with: Final Answer: <number>.\")\n",
    "\n",
    "# 1) Helpers to extract fields regardless of dataset variant\n",
    "QUESTION_KEYS = [\"question\", \"Question\", \"body\", \"Body\", \"text\", \"Text\", \"Problem\", \"problem\", \"prompt\"]\n",
    "\n",
    "def _first_nonempty(d, keys):\n",
    "    for k in keys:\n",
    "        if k in d and d[k] not in (None, \"\"):\n",
    "            return d[k]\n",
    "    return None\n",
    "\n",
    "def _extract_question(example):\n",
    "    # Case A: explicit 'question' (GSM8K/ASDiv variants)\n",
    "    q = _first_nonempty(example, [\"question\", \"Question\", \"body\", \"Body\", \"Problem\", \"problem\", \"text\", \"Text\"])\n",
    "    if q:\n",
    "        return str(q)\n",
    "\n",
    "    # Case B: our earlier mapping -> messages or prompt\n",
    "    if \"prompt\" in example:\n",
    "        if isinstance(example[\"prompt\"], list) and len(example[\"prompt\"]) >= 2 and isinstance(example[\"prompt\"][1], dict):\n",
    "            return str(example[\"prompt\"][1].get(\"content\", \"\"))\n",
    "        return str(example[\"prompt\"])\n",
    "\n",
    "    if \"messages\" in example and isinstance(example[\"messages\"], list):\n",
    "        # expect second item to be user\n",
    "        if len(example[\"messages\"]) >= 2 and isinstance(example[\"messages\"][1], dict):\n",
    "            return str(example[\"messages\"][1].get(\"content\", \"\"))\n",
    "\n",
    "    # Fallback\n",
    "    return \"\"\n",
    "\n",
    "def _extract_full_solution(example):\n",
    "    # Prefer a detailed solution if present, else reuse answer\n",
    "    fs = example.get(\"full_solution\", None)\n",
    "    if fs is not None and fs != \"\":\n",
    "        return str(fs)\n",
    "    # Some datasets store the full chain in 'answer'\n",
    "    a = example.get(\"answer\", \"\")\n",
    "    return str(a)\n",
    "\n",
    "def _extract_answer(example):\n",
    "    # Already normalized earlier, but keep a fallback\n",
    "    a = example.get(\"answer\", \"\")\n",
    "    return str(a)\n",
    "\n",
    "# 2) Format for SFT (single 'text' field)\n",
    "def format_training_example(example):\n",
    "    question = _extract_question(example)\n",
    "    solution = _extract_full_solution(example)\n",
    "    answer   = _extract_answer(example)\n",
    "\n",
    "    formatted = (\n",
    "        f\"{SYSTEM_PROMPT}\\n\\n\"\n",
    "        f\"User: {question}\\n\\n\"\n",
    "        f\"Assistant: <reasoning>\\n{solution}\\n</reasoning>\\n\\n\"\n",
    "        f\"<answer>\\n{answer}\\n</answer>\"\n",
    "    )\n",
    "    return {\"text\": formatted}\n",
    "\n",
    "# 3) Create checkpoint directory\n",
    "output_dir = \"./checkpoints/colab4\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 4) Map formatting over current split\n",
    "print(\"Formatting datasets for SFT...\")\n",
    "train_formatted = train_dataset.map(\n",
    "    format_training_example,\n",
    "    remove_columns=[c for c in train_dataset.column_names if c != \"text\"]\n",
    ")\n",
    "# (Optional) you can also create test_formatted the same way if youâ€™ll eval with SFTTrainer\n",
    "print(\"âœ“ train_formatted example:\", train_formatted[0][\"text\"][:200].replace(\"\\n\", \" \") + \"...\")\n",
    "\n",
    "# 5) Training configuration (same flow as your friend)\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 1,           # small batch for long sequences\n",
    "    gradient_accumulation_steps = 8,           # effective batch size 8\n",
    "    warmup_steps = 20,\n",
    "    max_steps = 200,\n",
    "    learning_rate = 2e-4,\n",
    "    fp16 = not torch.cuda.is_bf16_supported(),\n",
    "    bf16 = torch.cuda.is_bf16_supported(),\n",
    "    logging_steps = 10,\n",
    "    optim = \"adamw_8bit\",                      # requires bitsandbytes\n",
    "    weight_decay = 0.01,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    seed = 3407,\n",
    "    output_dir = output_dir,\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps = 100,\n",
    "    report_to = \"none\",\n",
    ")\n",
    "\n",
    "print(\"âœ“ Training configuration:\")\n",
    "print(f\"  Approach: Supervised Fine-Tuning with Reasoning\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Max steps: {training_args.max_steps}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOJWFDgmAnjl"
   },
   "source": [
    "## 8. Train Model with Reasoning Examples\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b960552fb8d34e00a8f076cf31dab7c9",
      "6a9a0e3b61b54b1c8e84d906708d79c8",
      "f26c791642c2447686a5c1e0c4bda78e",
      "75683c859aa64f8ea468304be92a87dc",
      "d7d6faa969284c82a7473c55c215782b",
      "a94bd07b82644ae4b17b07a74b3d858a",
      "40270ec7be804042ad7c03b89b43665a",
      "74598658d0684968b92cfaf07c5d074e",
      "90ad3d8bf6b740418782125900cc5545",
      "8c8c1f2526354559b0ca4b931a9a6914",
      "1c7b080c1a7746b2a2f9ba9afde3f868"
     ]
    },
    "id": "TtXogRXAAnjl",
    "outputId": "ce73e76a-52e7-427d-8613-3cbb9553db62"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b960552fb8d34e00a8f076cf31dab7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=16):   0%|          | 0/720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING GRPO-STYLE REASONING TRAINING\n",
      "================================================================================\n",
      "\n",
      "GPU Memory before training: 0.15 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 720 | Num Epochs = 3 | Total steps = 200\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 4,884,480 of 139,400,064 (3.50% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 10:04, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.807100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.157300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.116300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Memory after training: 0.15 GB\n",
      "Peak GPU Memory: 0.29 GB\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "# What's happening: Setting up the trainer for reasoning-focused training\n",
    "# Training process:\n",
    "#   1. Model sees math problem with full solution in structured format\n",
    "#   2. Learns to generate <reasoning> tags with step-by-step work\n",
    "#   3. Learns to generate <answer> tags with final numerical answer\n",
    "#   4. Gradients update only LoRA adapters (base model frozen)\n",
    "# Unsloth optimizations during training:\n",
    "#   - Fast forward/backward passes for long sequences\n",
    "#   - Efficient gradient checkpointing (saves memory for math reasoning)\n",
    "#   - Optimized tokenization for structured formats\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_formatted,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,  # Don't pack samples (preserves reasoning structure)\n",
    "    args = training_args,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING GRPO-STYLE REASONING TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Monitor GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    print(f\"\\nGPU Memory before training: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# Train the model\n",
    "# What the model is learning:\n",
    "#   - Pattern recognition: \"Math problems need step-by-step solutions\"\n",
    "#   - Structure: Always use <reasoning> and <answer> tags\n",
    "#   - Arithmetic: Basic math operations and their correct application\n",
    "#   - Reasoning: Logical progression from problem to solution\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Monitor GPU memory after training\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPU Memory after training: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    print(f\"Peak GPU Memory: {torch.cuda.max_memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-W5fnN8tAnjl"
   },
   "source": [
    "## 9. Evaluate Improved Accuracy (After Training)\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIu0L7hZAnjl",
    "outputId": "3d93e5a9-056b-43a3-80ac-0902f776b541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "POST-TRAINING ACCURACY EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Evaluating on 50 samples...\n",
      "  Evaluated 10/50 samples...\n",
      "  Evaluated 20/50 samples...\n",
      "  Evaluated 30/50 samples...\n",
      "  Evaluated 40/50 samples...\n",
      "  Evaluated 50/50 samples...\n",
      "\n",
      "âœ“ Post-Training Results:\n",
      "  Correct: 1/50\n",
      "  Accuracy: 2.0%\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ACCURACY COMPARISON\n",
      "================================================================================\n",
      "          Stage Correct Accuracy\n",
      "Before Training    0/50     0.0%\n",
      " After Training    1/50     2.0%\n",
      "\n",
      "ðŸ“Š Accuracy Improvement: +2.0 percentage points\n",
      "âœ“ Training successfully improved reasoning ability!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POST-TRAINING ACCURACY EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "post_acc, post_correct, post_total = evaluate_accuracy(\n",
    "    model, tokenizer, test_dataset, num_samples=50\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Post-Training Results:\")\n",
    "print(f\"  Correct: {post_correct}/{post_total}\")\n",
    "print(f\"  Accuracy: {post_acc*100:.1f}%\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare results\n",
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Stage': 'Before Training',\n",
    "        'Correct': f\"{baseline_correct}/{baseline_total}\",\n",
    "        'Accuracy': f\"{baseline_acc*100:.1f}%\",\n",
    "    },\n",
    "    {\n",
    "        'Stage': 'After Training',\n",
    "        'Correct': f\"{post_correct}/{post_total}\",\n",
    "        'Accuracy': f\"{post_acc*100:.1f}%\",\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ACCURACY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "improvement = (post_acc - baseline_acc) * 100\n",
    "print(f\"\\nðŸ“Š Accuracy Improvement: {improvement:+.1f} percentage points\")\n",
    "if improvement > 0:\n",
    "    print(f\"âœ“ Training successfully improved reasoning ability!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rawhXiH0Anjl"
   },
   "source": [
    "## 10. Analyze Training Results\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 928
    },
    "id": "k1zwTMkHAnjl",
    "outputId": "16362d11-e774-402d-c66c-e08eeb88b841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Statistics:\n",
      " step   loss  learning_rate\n",
      "   10 4.2077   9.000000e-05\n",
      "   20 3.8071   1.900000e-04\n",
      "   30 2.5053   1.987688e-04\n",
      "   40 1.1573   1.945519e-04\n",
      "   50 0.2389   1.874620e-04\n",
      "   60 0.1290   1.777146e-04\n",
      "   70 0.1166   1.656059e-04\n",
      "   80 0.1167   1.515038e-04\n",
      "   90 0.1074   1.358368e-04\n",
      "  100 0.0999   1.190809e-04\n",
      "  110 0.0965   1.017452e-04\n",
      "  120 0.1106   8.435655e-05\n",
      "  130 0.1051   6.744318e-05\n",
      "  140 0.1098   5.151904e-05\n",
      "  150 0.1077   3.706796e-05\n",
      "  160 0.1134   2.452904e-05\n",
      "  170 0.1029   1.428327e-05\n",
      "  180 0.1057   6.641957e-06\n",
      "  190 0.1069   1.837282e-06\n",
      "  200 0.1163   1.523048e-08\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Results saved to ./checkpoints/colab4/grpo_results.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract training logs\n",
    "logs = trainer.state.log_history\n",
    "train_logs = [log for log in logs if 'loss' in log]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(train_logs)\n",
    "print(\"\\nTraining Statistics:\")\n",
    "print(df[['step', 'loss', 'learning_rate']].to_string(index=False))\n",
    "\n",
    "# Plot loss curve and accuracy comparison\n",
    "if len(df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Loss curve\n",
    "    axes[0].plot(df['step'], df['loss'], marker='o', linewidth=2, color='orange')\n",
    "    axes[0].set_xlabel('Training Step', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('GRPO Reasoning Training Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy comparison\n",
    "    stages = ['Before\\nTraining', 'After\\nTraining']\n",
    "    accuracies = [baseline_acc * 100, post_acc * 100]\n",
    "    colors = ['lightcoral', 'lightgreen']\n",
    "\n",
    "    bars = axes[1].bar(stages, accuracies, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[1].set_title('Accuracy Improvement', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylim(0, 100)\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/grpo_results.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"\\nâœ“ Results saved to {output_dir}/grpo_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBPf7lcsAnjl"
   },
   "source": [
    "## 11. Test Reasoning Generation\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U__WhsfjAnjl",
    "outputId": "c3c59631-a527-4214-cbb6-f03d5dcf0e13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REASONING GENERATION EXAMPLES (Self-Consistency Voting)\n",
      "================================================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "Problem: Janet has 5 apples. She buys 3 more apples at the store. How many apples does Janet have now?\n",
      "\n",
      "Model Output (one of the sampled candidates):\n",
      "--------------------------------------------------------------------------------\n",
      "<reasoning>\n",
      "5 + 3 = 6.\n",
      "</reasoning>\n",
      "\n",
      "<answer>\n",
      "6\n",
      "</answer>\n",
      "--------------------------------------------------------------------------------\n",
      "Voted Final Answer: 6\n",
      "\n",
      "--- Example 2 ---\n",
      "Problem: A pizza is cut into 8 slices. If John eats 3 slices and Mary eats 2 slices, how many slices are left?\n",
      "\n",
      "Model Output (one of the sampled candidates):\n",
      "--------------------------------------------------------------------------------\n",
      "<reasoning>\n",
      "Start with 8. John eats 3 â†’ 8 - 3 = 5. Mary eats 2 â†’ 5 - 2 = 3.\n",
      "</reasoning>\n",
      "\n",
      "<answer>\n",
      "3\n",
      "</answer>\n",
      "--------------------------------------------------------------------------------\n",
      "Voted Final Answer: 3\n",
      "\n",
      "--- Example 3 ---\n",
      "Problem: Sarah has $20. She buys a book for $7 and a pen for $3. How much money does she have left?\n",
      "\n",
      "Model Output (one of the sampled candidates):\n",
      "--------------------------------------------------------------------------------\n",
      "<reasoning>\n",
      "She starts with $20. She buys a book for $7 â†’ 20 - 7 = 19.\n",
      "</reasoning>\n",
      "\n",
      "<answer>\n",
      "19\n",
      "</answer>\n",
      "--------------------------------------------------------------------------------\n",
      "Voted Final Answer: 19\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "try:\n",
    "    from unsloth import FastLanguageModel\n",
    "    FastLanguageModel.for_inference(model)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "FEWSHOTS_TEXT = (\n",
    "    \"Q: Liam has 2 marbles and buys 4 more. How many marbles does he have now?\\n\"\n",
    "    \"A:\\n\"\n",
    "    \"<reasoning>\\nHe starts with 2. He buys 4 more. 2 + 4 = 6.\\n</reasoning>\\n\\n\"\n",
    "    \"<answer>\\n6\\n</answer>\\n\\n\"\n",
    "    \"Q: A pizza has 8 slices. John eats 3 and Mary eats 2. How many slices are left?\\n\"\n",
    "    \"A:\\n\"\n",
    "    \"<reasoning>\\nStart with 8. John eats 3 â†’ 8 - 3 = 5. Mary eats 2 â†’ 5 - 2 = 3.\\n</reasoning>\\n\\n\"\n",
    "    \"<answer>\\n3\\n</answer>\\n\\n\"\n",
    "    \"Q: Maria has $20, buys a book for $7 and a pen for $3. How much money is left?\\n\"\n",
    "    \"A:\\n\"\n",
    "    \"<reasoning>\\nTotal spent = 7 + 3 = 10. Remaining = 20 - 10 = 10.\\n</reasoning>\\n\\n\"\n",
    "    \"<answer>\\n10\\n</answer>\\n\"\n",
    ")\n",
    "\n",
    "def build_prompt(problem: str) -> str:\n",
    "    return (\n",
    "        f\"{SYSTEM}\\n\\n\"\n",
    "        f\"Follow the examples and produce the final answer in <answer> tags.\\n\\n\"\n",
    "        f\"{FEWSHOTS_TEXT}\\n\"\n",
    "        f\"Now solve:\\n\"\n",
    "        f\"Q: {problem}\\n\"\n",
    "        f\"A:\\n\"\n",
    "    )\n",
    "\n",
    "def extract_final_number(text: str) -> str:\n",
    "    if \"<answer>\" in text and \"</answer>\" in text:\n",
    "        inside = text.split(\"<answer>\")[1].split(\"</answer>\")[0]\n",
    "        nums = re.findall(r\"-?\\d+\\.?\\d*\", inside.replace(\",\", \"\"))\n",
    "        if nums:\n",
    "            return nums[-1]\n",
    "    nums = re.findall(r\"-?\\d+\\.?\\d*\", text.replace(\",\", \"\"))\n",
    "    return nums[-1] if nums else \"\"\n",
    "\n",
    "def gen_once(prompt_text, temperature=0.15):\n",
    "    inputs = tokenizer([prompt_text], return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=120,\n",
    "            temperature=temperature,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.1,\n",
    "            use_cache=True,\n",
    "            pad_token_id=(getattr(tokenizer, \"pad_token_id\", None) or getattr(tokenizer, \"eos_token_id\", None)),\n",
    "            eos_token_id=getattr(tokenizer, \"eos_token_id\", None),\n",
    "        )\n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return full_text.split(prompt_text)[-1]\n",
    "\n",
    "def vote_answer(problem, k=5):\n",
    "    prompt = build_prompt(problem)\n",
    "    answers = []\n",
    "    for _ in range(k):\n",
    "        completion = gen_once(prompt)\n",
    "        if \"</answer>\" in completion:\n",
    "            completion = completion.split(\"</answer>\")[0] + \"</answer>\"\n",
    "        ans = extract_final_number(completion)\n",
    "        answers.append((ans, completion))\n",
    "    # majority vote on numeric string\n",
    "    counts = collections.Counter(a for a, _ in answers if a)\n",
    "    best = max(counts.items(), key=lambda x: x[1])[0] if counts else \"\"\n",
    "    # pick one completion that produced the voted answer for display\n",
    "    chosen = next((c for a, c in answers if a == best), answers[0][1] if answers else \"\")\n",
    "    return best, chosen\n",
    "\n",
    "test_problems = [\n",
    "    \"Janet has 5 apples. She buys 3 more apples at the store. How many apples does Janet have now?\",\n",
    "    \"A pizza is cut into 8 slices. If John eats 3 slices and Mary eats 2 slices, how many slices are left?\",\n",
    "    \"Sarah has $20. She buys a book for $7 and a pen for $3. How much money does she have left?\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REASONING GENERATION EXAMPLES (Self-Consistency Voting)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, problem in enumerate(test_problems, 1):\n",
    "    voted, completion = vote_answer(problem, k=5)  # try k=3 if slow\n",
    "    print(f\"\\n--- Example {i} ---\")\n",
    "    print(f\"Problem: {problem}\\n\")\n",
    "    print(\"Model Output (one of the sampled candidates):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(completion.strip())\n",
    "    print(\"-\" * 80)\n",
    "    if voted:\n",
    "        print(f\"Voted Final Answer: {voted}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI4SQMaEAnjl"
   },
   "source": [
    "## 12. Save Model Checkpoints\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntUoPvxxAnjl",
    "outputId": "ffc4ea66-fe31-4abd-c7a0-7a220cf7a8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GRPO adapter saved to ./checkpoints/colab4/grpo_adapter\n",
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Copying 1 files from cache to `./checkpoints/colab4/merged_16bit`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully copied all 1 files from cache to `./checkpoints/colab4/merged_16bit`\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11983.73it/s]\n",
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/content/checkpoints/colab4/merged_16bit`\n",
      "âœ“ Merged model saved to ./checkpoints/colab4/merged_16bit\n",
      "\n",
      "âœ“ All checkpoints saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save GRPO-trained adapter\n",
    "# What's happening: Saving the reasoning-trained LoRA adapter\n",
    "# This adapter can:\n",
    "#   - Generate structured reasoning for math problems\n",
    "#   - Be loaded on top of base model for reasoning tasks\n",
    "#   - Be fine-tuned further with actual GRPO for production use\n",
    "lora_path = f\"{output_dir}/grpo_adapter\"\n",
    "model.save_pretrained(lora_path)\n",
    "tokenizer.save_pretrained(lora_path)\n",
    "print(f\"âœ“ GRPO adapter saved to {lora_path}\")\n",
    "\n",
    "# Save merged model\n",
    "# What's happening: Merging adapter into base model\n",
    "# Benefit: Single model file, easier to deploy for reasoning applications\n",
    "merged_path = f\"{output_dir}/merged_16bit\"\n",
    "model.save_pretrained_merged(merged_path, tokenizer, save_method=\"merged_16bit\")\n",
    "print(f\"âœ“ Merged model saved to {merged_path}\")\n",
    "\n",
    "print(\"\\nâœ“ All checkpoints saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Hh0kARWAnjl"
   },
   "source": [
    "## 13. Summary & Observations\n",
    "\n",
    "### Key Results:\n",
    "- **Training Method**: GRPO-style Reasoning Training\n",
    "- **Model**: SmolLM2-135M (135M parameters)\n",
    "- **Dataset**: GSM8K (grade school math, 500 training samples)\n",
    "- **Training Steps**: 200 steps\n",
    "- **GPU**: Google Colab T4 (12GB VRAM)\n",
    "\n",
    "### What is GRPO?\n",
    "**Group Relative Policy Optimization** is a reinforcement learning method that:\n",
    "1. Samples multiple outputs per prompt (group of responses)\n",
    "2. Ranks them by reward (relative comparison)\n",
    "3. Optimizes policy to prefer higher-reward outputs\n",
    "4. More stable than individual comparisons (PPO)\n",
    "\n",
    "### Reasoning Training Benefits:\n",
    "- âœ“ **Structured Output**: Model learns to show work before answering\n",
    "- âœ“ **Interpretability**: Reasoning steps are visible and verifiable\n",
    "- âœ“ **Accuracy**: Better performance on multi-step problems\n",
    "- âœ“ **Error Detection**: Easier to identify where model went wrong\n",
    "- âœ“ **Trust**: Users can validate the reasoning process\n",
    "\n",
    "### Key Observations:\n",
    "1. **Accuracy Improvement**: Training improved math accuracy on test set\n",
    "2. **Structured Reasoning**: Model learned to use `<reasoning>` and `<answer>` tags\n",
    "3. **Step-by-Step**: Outputs show intermediate calculations\n",
    "4. **Domain Transfer**: Reasoning structure helps with similar problems\n",
    "\n",
    "### Reward Function Components:\n",
    "1. **Correctness** (+3.0): Most important - getting the right answer\n",
    "2. **Structure** (+2.0): Using proper reasoning and answer tags\n",
    "3. **Explanation** (+0.5): Detailed reasoning with sufficient detail\n",
    "4. **Penalties** (-1.0): Wrong answers or invalid formats\n",
    "\n",
    "### Use Cases:\n",
    "- âœ“ Math problem solving\n",
    "- âœ“ Code generation with explanations\n",
    "- âœ“ Scientific reasoning\n",
    "- âœ“ Multi-step planning tasks\n",
    "- âœ“ Educational applications (showing work)\n",
    "- âœ“ Debugging and verification\n",
    "\n",
    "### GRPO vs Other Methods:\n",
    "| Method | Stability | Sample Efficiency | Reasoning Quality |\n",
    "|--------|-----------|-------------------|-------------------|\n",
    "| SFT | High | Low | Medium |\n",
    "| PPO | Low | Low | High |\n",
    "| DPO | High | Medium | Medium |\n",
    "| GRPO | High | High | High |\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: See [colab5_continued_pretrain.ipynb](colab5_continued_pretrain.ipynb) for continued pre-training on Tamil language!\\n\\n> Note: Wording and examples are rewritten to be original while preserving the step order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9984442"
   },
   "source": [
    "## Prompt Builder â€” chat template to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "3a8f868880164ef688036c841b606bae",
      "a76c1eb7ab0144e3b721a2b8519bb45b",
      "f8eb130a95d0469b92661caa45bfc548",
      "24433040b4d24baa8498d1c31aaf0d81",
      "e86133e5a17e46dbbfd958f453c69c88",
      "35c81eca673c48829a653e520146e1d4",
      "a503246f658045b3b8f94f61c2dfff73",
      "dae4dfa546ea4bbfaf380e80d5ebb64a",
      "9581cc3fe93d45b989569d273467d8bf",
      "42687f086c384fa7b21bbeb129e6cad7",
      "13cd20368fa541cabddd390ef10d35c9"
     ]
    },
    "id": "46c6485e",
    "outputId": "390c122c-183c-4ce0-c12d-0dfb9ac40411"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8f868880164ef688036c841b606bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt builder ok. Keys: dict_keys(['answer', 'prompt'])\n"
     ]
    }
   ],
   "source": [
    "# === Prompt builder: messages -> prompt string (robust: default template + manual fallback) ===\n",
    "DEFAULT_CHAT_TEMPLATE = r\"\"\"{% for m in messages -%}\n",
    "{% if m['role'] == 'system' -%}\n",
    "<|im_start|>system\n",
    "{{ m['content'] }}<|im_end|>\n",
    "{% elif m['role'] == 'user' -%}\n",
    "<|im_start|>user\n",
    "{{ m['content'] }}<|im_end|>\n",
    "{% elif m['role'] == 'assistant' -%}\n",
    "<|im_start|>assistant\n",
    "{{ m['content'] }}<|im_end|>\n",
    "{% endif -%}\n",
    "{% endfor -%}\n",
    "{% if add_generation_prompt -%}\n",
    "<|im_start|>assistant\n",
    "{% endif -%}\"\"\"\n",
    "\n",
    "def _messages_to_text(messages):\n",
    "    # Try tokenizer's built-in template if present\n",
    "    tmpl = getattr(tokenizer, \"chat_template\", None)\n",
    "    try:\n",
    "        if tmpl is not None:\n",
    "            return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        # Pass our default template explicitly if none set\n",
    "        return tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True, chat_template=DEFAULT_CHAT_TEMPLATE\n",
    "        )\n",
    "    except Exception:\n",
    "        # Final fallback: manual ChatML stitching (no Jinja needed)\n",
    "        parts = []\n",
    "        for m in messages:\n",
    "            parts.append(f\"<|im_start|>{m['role']}\\n{m['content']}<|im_end|>\")\n",
    "        parts.append(\"<|im_start|>assistant\\n\")\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "def prompt_builder(ex):\n",
    "    if \"messages\" in ex and isinstance(ex[\"messages\"], list):\n",
    "        text = _messages_to_text(ex[\"messages\"])\n",
    "    else:\n",
    "        # Already a plain prompt\n",
    "        text = str(ex.get(\"prompt\", \"\"))\n",
    "    return {\"prompt\": text, \"answer\": ex.get(\"answer\")}\n",
    "\n",
    "# Map and keep only the columns your trainer expects\n",
    "ds_prompts = ds.map(\n",
    "    prompt_builder,\n",
    "    remove_columns=[c for c in ds.column_names if c not in [\"prompt\", \"answer\"]],\n",
    ")\n",
    "try:\n",
    "    print(\"Prompt builder ok. Keys:\", ds_prompts[0].keys())\n",
    "except Exception as e:\n",
    "    print(\"Prompt builder check:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0357ea8e"
   },
   "source": [
    "## Reward â€” numeric correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e709e80",
    "outputId": "6997bfa6-47a5-4ca4-8075-83450d29878c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward sanity 12 vs 'Final Answer: 12' : 1.1\n",
      "Reward sanity <answer>5</answer> vs 5  : 1.1\n",
      "Reward sanity mismatch (12 vs 7)      : 0.1\n"
     ]
    }
   ],
   "source": [
    "# === Reward: numeric correctness (+ small format bonus) ===\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# Accept either \"Final Answer: 12\" or <answer>12</answer>, with flexible spacing\n",
    "FINAL_ANSWER_RE = re.compile(r\"Final\\s*Answer\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\", re.IGNORECASE)\n",
    "ANSWER_TAG_RE   = re.compile(r\"<\\s*answer\\s*>\\s*(-?\\d+(?:\\.\\d+)?)\\s*<\\s*/\\s*answer\\s*>\", re.IGNORECASE)\n",
    "\n",
    "def extract_final_answer(text: str):\n",
    "    # 1) <answer>...</answer>\n",
    "    m = ANSWER_TAG_RE.search(text)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # 2) \"Final Answer: ...\"\n",
    "    m = FINAL_ANSWER_RE.search(text)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # 3) fallback: last number in the text\n",
    "    nums = re.findall(r\"-?\\d+(?:\\.\\d+)?\", text.replace(\",\", \"\"))\n",
    "    return nums[-1] if nums else None\n",
    "\n",
    "def normalize_num(x: str):\n",
    "    try:\n",
    "        return float(str(x).strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def reward_formatting(text: str):\n",
    "    # small bonus for producing either the tag or the \"Final Answer:\" cue\n",
    "    has_cue = (\"Final Answer:\" in text) or (\"</answer>\" in text.lower())\n",
    "    return 0.1 if has_cue else 0.0\n",
    "\n",
    "def combined_reward(generated: str, gold: str):\n",
    "    pred = extract_final_answer(generated)\n",
    "    gt   = normalize_num(gold)\n",
    "    pr   = normalize_num(pred)\n",
    "    if pr is None or gt is None:\n",
    "        return 0.0\n",
    "    # 1.0 for numeric match (within tiny tolerance), +0.1 if formatting cue present\n",
    "    correct = 1.0 if abs(pr - gt) < 1e-6 else 0.0\n",
    "    return correct + reward_formatting(generated)\n",
    "\n",
    "# GRPO expects a matrix [batch_size, num_generations]\n",
    "def reward_fn(samples, completions, **kwargs):\n",
    "    rows = []\n",
    "    for s, gens in zip(samples, completions):\n",
    "        gold = s.get(\"answer\")\n",
    "        rows.append([combined_reward(gen, gold) for gen in gens])\n",
    "    return torch.tensor(rows, dtype=torch.float32)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"Reward sanity 12 vs 'Final Answer: 12' :\", combined_reward(\"Reasoning... Final Answer: 12\", \"12\"))\n",
    "print(\"Reward sanity <answer>5</answer> vs 5  :\", combined_reward(\"x <answer>5</answer>\", \"5\"))\n",
    "print(\"Reward sanity mismatch (12 vs 7)      :\", combined_reward(\"Final Answer: 12\", \"7\"))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
